---
layout: post
title: Scrapy系列教程(一):Scrapy的介绍
date: 2017-12-27
tag: Scrapy系列教程
---



### 什么是Scrapy ?

> Scrapy，Python开发的一个快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试
>
> Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等，最新版本又提供了web2.0爬虫的支持。
>
> Scrap，是碎片的意思，这个Python的爬虫框架叫Scrapy。    (摘自百度百科)

<p></p>

### Scrapy的特点

  *  基于框架,scrapy对千万级URL去重支持很好,适合爬取海量的数据内容
  *  适合与爬取静态网页,对于动态网页不适合(不是说不行)



### Scrapy的架构图:



![](http://p0kzdnfmg.bkt.clouddn.com/17-12-23/44520710.jpg)



- `Scrapy Engine(引擎)`: 如果把 Scrapy 比作一个蚂蚁窝,那么这个`Scrapy Engine` 就是蚁后 它就是最大的 boss ,负责`Spider`、`ItemPipeline`、`Downloader`、`Scheduler`中间的通讯，信号、数据传递等

- `Scheduler(调度器)`: 它负责接受`引擎`发送过来的Request请求，并按照一定的方式进行整理排列，入队，当`引擎`需要时，交还给`引擎`。

- `Downloader（下载器）`：负责下载`Scrapy Engine(引擎)`发送的所有Requests请求，并将其获取到的Responses交还给`Scrapy Engine(引擎)`，由`引擎`交给`Spider`来处理

- `Spider（爬虫）`：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给`引擎`，再次进入`Scheduler(调度器)`，还是上面的例子,`Spider`就相当工蚁,所以的粗活累活都被他承包了 ,他负责去寻找食物(即我们要爬取的网页)

- `Item Pipeline(管道)`：它负责处理`Spider`中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.

- `Downloader Middlewares（下载中间件）`：你可以当作是一个可以自定义扩展下载功能的组件。

- `Spider Middlewares（Spider中间件）`：你可以理解为是一个可以自定扩展和操作`引擎`和`Spider`中间`通信`的功能组件（比如进入`Spider`的Responses;和从`Spider`出去的Requests）









