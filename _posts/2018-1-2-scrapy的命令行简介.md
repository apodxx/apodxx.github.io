---
layout: post
title: Scrapy系列教程(四):Scrapy常用命令行工具
date: 2018-1-2
tag: Scrapy系列教程 
---



### 简介

scrapy 内置了很多命令,在这一篇中,介绍一些简单的使用命令,如图 当我们在命令行下`scrapy`后,所有的命令列表:

![](http://p0kzdnfmg.bkt.clouddn.com/18-1-4/30075377.jpg)

### 常用命令

* **startproject** 

  新建一个工程

  ```
  scrapy startproject douyu_crawl
  ```

  在上面创建了一个名称为`douyu_crawl`的scrapy工程

  ![](http://p0kzdnfmg.bkt.clouddn.com/18-1-4/15764707.jpg)

  上面最后两行告诉我们的便是在进入douyu_crawl文件夹后,使用`genspider`创建一个爬虫

  ![](http://p0kzdnfmg.bkt.clouddn.com/18-1-4/45985374.jpg)

  此时我们看到的便是我们创建后 显示的树形图

* **genspider**

  构建一个爬虫,需要注意的是,*一个爬虫项目可以有多个爬虫,但是名字必须唯一*

  ```
  scrapy genspider douyu douyu.com
  ```

  在上面我创建了一个名字叫`douyu`的爬虫,要爬去的网址是www.douyu.com

  ![](http://p0kzdnfmg.bkt.clouddn.com/18-1-4/26538054.jpg)

  上面显示的便是创建完爬虫后显示的爬虫结构,我们看到比之上面的图,多出了douyu.py这个文件,这个就是我们要在里面主要写的爬虫文件

* **crawl**

  当我们写完爬虫文件后,运行爬虫文件,便需要此命令

  ```
  scrapy crawl douyu
  ```

  我们写的上面的内容便是我们要爬取`doyu`这个爬虫

* **shell**

  这个命令将是我们后来用到的最多的命令,之前我们安装了`ipython`便是用于此,他是一个是非常好用的一个测试工具。我们可以使用此方法来进行爬虫的工作

  ```
  scrapy shell douyu.com
  ```

  ![](http://p0kzdnfmg.bkt.clouddn.com/18-1-4/25579314.jpg)

  部分截图

  ![](http://p0kzdnfmg.bkt.clouddn.com/18-1-4/35756846.jpg)

  可以看到我们我们熟悉的ipython界面,我们再此处对我们爬虫的网页进行操作

  例如`response.text`显示爬取网页的内容,`response.xpath('')`可以使用xpath来获取我们要匹配的内容,更多的内容我们会在后面用的时候再说再次先挖一个坑吧~~

* **version**

  查看版本信息

* **check**

  ```
  scrapy check douyu
  ```

  ​

  ​	检查爬虫的是否完整

  ![](http://p0kzdnfmg.bkt.clouddn.com/18-1-4/4627931.jpg)

  如图这说明douyu这个爬虫是完整的

* **list**

  显示的是当前存在的工程有多少个爬虫

  ```
  scrapy list
  ```

  ​

  掌握以上信心,基本就够我们使用的了,如果你对其他命令可以去[scrapy的官网](http://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/tutorial.html),上面对各个命令做了更加详细的说明,好了本期教程教程就到这里我们下期再见吧~~

  ​